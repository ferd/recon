searchNodes=[{"doc":"Recon, as a module, provides access to the high-level functionality contained in the Recon application. It has functions in five main categories: 1. State information Process information is everything that has to do with the general state of the node. Functions such as info/1 and info/3 are wrappers to provide more details than erlang:process_info/1 , while providing it in a production-safe manner. They have equivalents to erlang:process_info/2 in the functions info/2 and info/4 , respectively. proc_count/2 and proc_window/3 are to be used when you require information about processes in a larger sense: biggest consumers of given process information (say memory or reductions), either absolutely or over a sliding time window, respectively. bin_leak/1 is a function that can be used to try and see if your Erlang node is leaking refc binaries. See the function itself for more details. Functions to access node statistics, in a manner somewhat similar to what vmstats provides as a library. There are 3 of them: node_stats_print/2 , which displays them, node_stats_list/2 , which returns them in a list, and node_stats/4 , which provides a fold-like interface for stats gathering. For CPU usage specifically, see scheduler_usage/1 . 2. OTP tools This category provides tools to interact with pieces of OTP more easily. At this point, the only function included is get_state/1 , which works as a wrapper around get_state/2 , which works as a wrapper around sys:get_state/1 in R16B01, and provides the required functionality for older versions of Erlang. 3. Code Handling Specific functions are in recon for the sole purpose of interacting with source and compiled code. remote_load/1 and remote_load/2 will allow to take a local module, and load it remotely (in a diskless manner) on another Erlang node you're connected to. source/1 allows to print the source of a loaded module, in case it's not available in the currently running node. 4. Ports and Sockets To make it simpler to debug some network-related issues, recon contains functions to deal with Erlang ports (raw, file handles, or inet). Functions tcp/0 , udp/0 , sctp/0 , files/0 , and port_types/0 will list all the Erlang ports of a given type. The latter function prints counts of all individual types. Port state information can be useful to figure out why certain parts of the system misbehave. Functions such as port_info/1 and port_info/2 are wrappers to provide more similar or more details than erlang:port_info/1-2 , and, for inet ports, statistics and options for each socket. Finally, the functions inet_count/2 and inet_window/3 provide the absolute or sliding window functionality of proc_count/2 and proc_window/3 to inet ports and connections currently on the node. 5. RPC These are wrappers to make RPC work simpler with clusters of Erlang nodes. Default RPC mechanisms (from the rpc module) make it somewhat painful to call shell-defined funs over node boundaries. The functions rpc/1 , rpc/2 , and rpc/3 will do it with a simpler interface. Additionally, when you're running diagnostic code on remote nodes and want to know which node evaluated what result, using named_rpc/1 , named_rpc/2 , and named_rpc/3 will wrap the results in a tuple that tells you which node it's coming from, making it easier to identify bad nodes.","ref":"recon.html","title":"recon","type":"module"},{"doc":"Refc binaries can be leaking when barely-busy processes route them around and do little else, or when extremely busy processes reach a stable amount of memory allocated and do the vast majority of their work with refc binaries. When this happens, it may take a very long while before references get deallocated and refc binaries get to be garbage collected, leading to Out Of Memory crashes. This function fetches the number of refc binary references in each process of the node, garbage collects them, and compares the resulting number of references in each of them. The function then returns the N processes that freed the biggest amount of binaries, potentially highlighting leaks. See The efficiency guide for more details on refc binaries","ref":"recon.html#bin_leak/1","title":"recon.bin_leak/1","type":"function"},{"doc":"returns a list of all file handles open on the node.","ref":"recon.html#files/0","title":"recon.files/0","type":"function"},{"doc":"Shorthand call to recon:get_state(PidTerm, 5000)","ref":"recon.html#get_state/1","title":"recon.get_state/1","type":"function"},{"doc":"Fetch the internal state of an OTP process. Calls sys:get_state/2 directly in R16B01+, and fetches it dynamically on older versions of OTP.","ref":"recon.html#get_state/2","title":"recon.get_state/2","type":"function"},{"doc":"Fetches a given attribute from all inet ports (TCP, UDP, SCTP) and returns the biggest Num consumers. The values to be used can be the number of octets (bytes) sent, received, or both ( send_oct , recv_oct , oct , respectively), or the number of packets sent, received, or both ( send_cnt , recv_cnt , cnt , respectively). Individual absolute values for each metric will be returned in the 3rd position of the resulting tuple.","ref":"recon.html#inet_count/2","title":"recon.inet_count/2","type":"function"},{"doc":"Fetches a given attribute from all inet ports (TCP, UDP, SCTP) and returns the biggest entries, over a sliding time window. Warning: this function depends on data gathered at two snapshots, and then building a dictionary with entries to differentiate them. This can take a heavy toll on memory when you have many dozens of thousands of ports open. The values to be used can be the number of octets (bytes) sent, received, or both ( send_oct , recv_oct , oct , respectively), or the number of packets sent, received, or both ( send_cnt , recv_cnt , cnt , respectively). Individual absolute values for each metric will be returned in the 3rd position of the resulting tuple.","ref":"recon.html#inet_window/3","title":"recon.inet_window/3","type":"function"},{"doc":"Allows to be similar to erlang:process_info/1 , but excludes fields such as the mailbox, which have a tendency to grow and be unsafe when called in production systems. Also includes a few more fields than what is usually given ( monitors , monitored_by , etc.), and separates the fields in a more readable format based on the type of information contained. Moreover, it will fetch and read information on local processes that were registered locally (an atom), globally ( {global, Name} ), or through another registry supported in the {via, Module, Name} syntax (must have a Module:whereis_name/1 function). Pids can also be passed in as a string ( &quot;&lt;0.39.0&gt;&quot; ) or a triple ( {0,39,0} ) and will be converted to be used. Returns undefined as a value when a process died.","ref":"recon.html#info/1","title":"recon.info/1","type":"function"},{"doc":"Allows to be similar to erlang:process_info/2 , but allows to sort fields by safe categories and pre-selections, avoiding items such as the mailbox, which may have a tendency to grow and be unsafe when called in production systems. Moreover, it will fetch and read information on local processes that were registered locally (an atom), globally ( {global, Name} ), or through another registry supported in the {via, Module, Name} syntax (must have a Module:whereis_name/1 function). Pids can also be passed in as a string ( &quot;&lt;0.39.0&gt;&quot; ) or a triple ( {0,39,0} ) and will be converted to be used. Although the type signature doesn't show it in generated documentation, a list of arguments or individual arguments accepted by erlang:process_info/2 and return them as that function would. A fake attribute binary_memory is also available to return the amount of memory used by refc binaries for a process.","ref":"recon.html#info/2","title":"recon.info/2","type":"function"},{"doc":"Equivalent to info(&lt;A.B.C&gt;) where A , B , and C are integers part of a pid","ref":"recon.html#info/3","title":"recon.info/3","type":"function"},{"doc":"Equivalent to info(&lt;A.B.C&gt;, Key) where A , B , and C are integers part of a pid","ref":"recon.html#info/4","title":"recon.info/4","type":"function"},{"doc":"Shorthand for named_rpc([node()|nodes()], Fun) .","ref":"recon.html#named_rpc/1","title":"recon.named_rpc/1","type":"function"},{"doc":"Shorthand for named_rpc(Nodes, Fun, infinity) .","ref":"recon.html#named_rpc/2","title":"recon.named_rpc/2","type":"function"},{"doc":"Runs an arbitrary fun (of arity 0) over one or more nodes, and returns the name of the node that computed a given result along with it, in a tuple.","ref":"recon.html#named_rpc/3","title":"recon.named_rpc/3","type":"function"},{"doc":"Gathers statistics N time, waiting Interval milliseconds between each run, and accumulates results using a folding function FoldFun . The function will gather statistics in two forms: Absolutes and Increments. Absolutes are values that keep changing with time, and are useful to know about as a datapoint: process count, size of the run queue, error_logger queue length in versions before OTP-21 or those thar run it explicitly, and the memory of the node (total, processes, atoms, binaries, and ets tables). Increments are values that are mostly useful when compared to a previous one to have an idea what they're doing, because otherwise they'd never stop increasing: bytes in and out of the node, number of garbage collector runs, words of memory that were garbage collected, and the global reductions count for the node.","ref":"recon.html#node_stats/4","title":"recon.node_stats/4","type":"function"},{"doc":"Shorthand for node_stats(N, Interval, fun(X,Acc) -&gt; [X|Acc] end, []) with the results reversed to be in the right temporal order.","ref":"recon.html#node_stats_list/2","title":"recon.node_stats_list/2","type":"function"},{"doc":"Shorthand for node_stats(N, Interval, fun(X,_) -&gt; io:format(&quot;~p~n&quot;,[X]) end, nostate) .","ref":"recon.html#node_stats_print/2","title":"recon.node_stats_print/2","type":"function"},{"doc":"Allows to be similar to erlang:port_info/1 , but allows more flexible port usage: usual ports, ports that were registered locally (an atom), ports represented as strings ( &quot;#Port&lt;0.2013&gt;&quot; ), or through an index lookup ( 2013 , for the same result as &quot;#Port&lt;0.2013&gt;&quot; ). Moreover, the function will try to fetch implementation-specific details based on the port type (only inet ports have this feature so far). For example, TCP ports will include information about the remote peer, transfer statistics, and socket options being used. The information-specific and the basic port info are sorted and categorized in broader categories ( port_info_type() ).","ref":"recon.html#port_info/1","title":"recon.port_info/1","type":"function"},{"doc":"Allows to be similar to erlang:port_info/2 , but allows more flexible port usage: usual ports, ports that were registered locally (an atom), ports represented as strings ( &quot;#Port&lt;0.2013&gt;&quot; ), or through an index lookup ( 2013 , for the same result as &quot;#Port&lt;0.2013&gt;&quot; ). Moreover, the function allows to to fetch information by category as defined in port_info_type() , and although the type signature doesn't show it in the generated documentation, individual items accepted by erlang:port_info/2 are accepted, and lists of them too.","ref":"recon.html#port_info/2","title":"recon.port_info/2","type":"function"},{"doc":"Shows a list of all different ports on the node with their respective types.","ref":"recon.html#port_types/0","title":"recon.port_types/0","type":"function"},{"doc":"Fetches a given attribute from all processes (except the caller) and returns the biggest Num consumers.","ref":"recon.html#proc_count/2","title":"recon.proc_count/2","type":"function"},{"doc":"Fetches a given attribute from all processes (except the caller) and returns the biggest entries, over a sliding time window. This function is particularly useful when processes on the node are mostly short-lived, usually too short to inspect through other tools, in order to figure out what kind of processes are eating through a lot resources on a given node. It is important to see this function as a snapshot over a sliding window. A program's timeline during sampling might look like this: --w---- [Sample1] ---x-------------y----- [Sample2] ---z---&gt; Some processes will live between w and die at x , some between y and z , and some between x and y . These samples will not be too significant as they're incomplete. If the majority of your processes run between a time interval x ... y (in absolute terms), you should make sure that your sampling time is smaller than this so that for many processes, their lifetime spans the equivalent of w and z . Not doing this can skew the results: long-lived processes, that have 10 times the time to accumulate data (say reductions) will look like bottlenecks when they're not one. Warning: this function depends on data gathered at two snapshots, and then building a dictionary with entries to differentiate them. This can take a heavy toll on memory when you have many dozens of thousands of processes.","ref":"recon.html#proc_window/3","title":"recon.proc_window/3","type":"function"},{"doc":"Equivalent to remote_load(nodes(), Mod) .","ref":"recon.html#remote_load/1","title":"recon.remote_load/1","type":"function"},{"doc":"Loads one or more modules remotely, in a diskless manner. Allows to share code loaded locally with a remote node that doesn't have it","ref":"recon.html#remote_load/2","title":"recon.remote_load/2","type":"function"},{"doc":"Shorthand for rpc([node()|nodes()], Fun) .","ref":"recon.html#rpc/1","title":"recon.rpc/1","type":"function"},{"doc":"Shorthand for rpc(Nodes, Fun, infinity) .","ref":"recon.html#rpc/2","title":"recon.rpc/2","type":"function"},{"doc":"Runs an arbitrary fun (of arity 0) over one or more nodes.","ref":"recon.html#rpc/3","title":"recon.rpc/3","type":"function"},{"doc":"Because Erlang CPU usage as reported from top isn't the most reliable value (due to schedulers doing idle spinning to avoid going to sleep and impacting latency), a metric exists that is based on scheduler wall time. For any time interval, Scheduler wall time can be used as a measure of how 'busy' a scheduler is. A scheduler is busy when: executing process code executing driver code executing NIF code executing BIFs garbage collecting doing memory management A scheduler isn't busy when doing anything else.","ref":"recon.html#scheduler_usage/1","title":"recon.scheduler_usage/1","type":"function"},{"doc":"returns a list of all SCTP ports (the data type) open on the node.","ref":"recon.html#sctp/0","title":"recon.sctp/0","type":"function"},{"doc":"Obtain the source code of a module compiled with debug_info . The returned list sadly does not allow to format the types and typed records the way they look in the original module, but instead goes to an intermediary form used in the AST. They will still be placed in the right module attributes, however.","ref":"recon.html#source/1","title":"recon.source/1","type":"function"},{"doc":"returns a list of all TCP ports (the data type) open on the node.","ref":"recon.html#tcp/0","title":"recon.tcp/0","type":"function"},{"doc":"returns a list of all UDP ports (the data type) open on the node.","ref":"recon.html#udp/0","title":"recon.udp/0","type":"function"},{"doc":"","ref":"recon.html#t:inet_attrs/0","title":"recon.inet_attrs/0","type":"type"},{"doc":"","ref":"recon.html#t:info_key/0","title":"recon.info_key/0","type":"type"},{"doc":"","ref":"recon.html#t:info_location_key/0","title":"recon.info_location_key/0","type":"type"},{"doc":"","ref":"recon.html#t:info_memory_key/0","title":"recon.info_memory_key/0","type":"type"},{"doc":"","ref":"recon.html#t:info_meta_key/0","title":"recon.info_meta_key/0","type":"type"},{"doc":"","ref":"recon.html#t:info_signals_key/0","title":"recon.info_signals_key/0","type":"type"},{"doc":"","ref":"recon.html#t:info_type/0","title":"recon.info_type/0","type":"type"},{"doc":"","ref":"recon.html#t:info_work_key/0","title":"recon.info_work_key/0","type":"type"},{"doc":"","ref":"recon.html#t:pid_term/0","title":"recon.pid_term/0","type":"type"},{"doc":"","ref":"recon.html#t:port_info_io_key/0","title":"recon.port_info_io_key/0","type":"type"},{"doc":"","ref":"recon.html#t:port_info_key/0","title":"recon.port_info_key/0","type":"type"},{"doc":"","ref":"recon.html#t:port_info_memory_key/0","title":"recon.port_info_memory_key/0","type":"type"},{"doc":"","ref":"recon.html#t:port_info_meta_key/0","title":"recon.port_info_meta_key/0","type":"type"},{"doc":"","ref":"recon.html#t:port_info_signals_key/0","title":"recon.port_info_signals_key/0","type":"type"},{"doc":"","ref":"recon.html#t:port_info_specific_key/0","title":"recon.port_info_specific_key/0","type":"type"},{"doc":"","ref":"recon.html#t:port_info_type/0","title":"recon.port_info_type/0","type":"type"},{"doc":"","ref":"recon.html#t:port_term/0","title":"recon.port_term/0","type":"type"},{"doc":"","ref":"recon.html#t:proc_attrs/0","title":"recon.proc_attrs/0","type":"type"},{"doc":"Functions to deal with Erlang's memory allocators , or particularly, to try to present the allocator data in a way that makes it simpler to discover possible problems. Tweaking Erlang memory allocators and their behaviour is a very tricky ordeal whenever you have to give up the default settings. This module (and its documentation) will try and provide helpful pointers to help in this task. This module should mostly be helpful to figure out if there is a problem, but will offer little help to figure out what is wrong. To figure this out, you need to dig deeper into the allocator data (obtainable with allocators/1 ), and/or have some precise knowledge about the type of load and work done by the VM to be able to assess what each reaction to individual tweak should be. A lot of trial and error might be required to figure out if tweaks have helped or not, ultimately. In order to help do offline debugging of memory allocator problems recon_alloc also has a few functions that store snapshots of the memory statistics. These snapshots can be used to freeze the current allocation values so that they do not change during analysis while using the regular functionality of this module, so that the allocator values can be saved, or that they can be shared, dumped, and reloaded for further analysis using files. See snapshot_load/1 for a simple use-case. Glossary: sys_alloc System allocator, usually just malloc mseg_alloc Used by other allocators, can do mmap. Caches allocations temp_alloc Used for temporary allocations eheap_alloc Heap data (i.e. process heaps) allocator binary_alloc Global binary heap allocator ets_alloc ETS data allocator driver_alloc Driver data allocator sl_alloc Short-lived memory blocks allocator ll_alloc Long-lived data (i.e. Erlang code itself) allocator fix_alloc Frequently used fixed-size data allocator std_alloc Allocator for other memory blocks carrier When a given area of memory is allocated by the OS to the VM (through sys_alloc or mseg_alloc), it is put into a 'carrier'. There are two kinds of carriers: multiblock and single block. The default carriers data is sent to are multiblock carriers, owned by a specific allocator (ets_alloc, binary_alloc, etc.). The specific allocator can thus do allocation for specific Erlang requirements within bits of memory that has been preallocated before. This allows more reuse, and we can even measure the cache hit rates cache_hit_rates/0 . There is however a threshold above which an item in memory won't fit a multiblock carrier. When that happens, the specific allocator does a special allocation to a single block carrier. This is done by the allocator basically asking for space directly from sys_alloc or mseg_alloc rather than a previously multiblock area already obtained before. This leads to various allocation strategies where you decide to choose: which multiblock carrier you're going to (if at all) which block in that carrier you're going to See the official documentation on erts_alloc for more details. mbcs Multiblock carriers. sbcs Single block carriers. lmbcs Largest multiblock carrier size smbcs Smallest multiblock carrier size sbct Single block carrier threshold By default all sizes returned by this module are in bytes. You can change this by calling set_unit/1 .","ref":"recon_alloc.html","title":"recon_alloc","type":"module"},{"doc":"returns a dump of all allocator settings and values","ref":"recon_alloc.html#allocators/0","title":"recon_alloc.allocators/0","type":"function"},{"doc":"returns a dump of all allocator settings and values modified depending on the argument. types report the settings and accumulated values for each allocator type. This is useful when looking for anomalies in the system as a whole and not specific instances.","ref":"recon_alloc.html#allocators/1","title":"recon_alloc.allocators/1","type":"function"},{"doc":"Checks all allocators in allocator() and returns the average block sizes being used for mbcs and sbcs . This value is interesting to use because it will tell us how large most blocks are. This can be related to the VM's largest multiblock carrier size ( lmbcs ) and smallest multiblock carrier size ( smbcs ) to specify allocation strategies regarding the carrier sizes to be used. This function isn't exceptionally useful unless you know you have some specific problem, say with sbcs/mbcs ratios (see sbcs_to_mbcs/1 ) or fragmentation for a specific allocator, and want to figure out what values to pick to increase or decrease sizes compared to the currently configured value. Do note that values for lmbcs and smbcs are going to be rounded up to the next power of two when configuring them.","ref":"recon_alloc.html#average_block_sizes/1","title":"recon_alloc.average_block_sizes/1","type":"function"},{"doc":"looks at the mseg_alloc allocator (allocator used by all the allocators in allocator() ) and returns information relative to the cache hit rates. Unless memory has expected spiky behaviour, it should usually be above 0.80 (80%). Cache can be tweaked using three VM flags: +MMmcs , +MMrmcbf , and +MMamcbf . +MMmcs stands for the maximum amount of cached memory segments. Its default value is '10' and can be anything from 0 to 30. Increasing it first and verifying if cache hits get better should be the first step taken. The two other options specify what are the maximal values of a segment to cache, in relative (in percent) and absolute terms (in kilobytes), respectively. Increasing these may allow more segments to be cached, but should also add overheads to memory allocation. An Erlang node that has limited memory and increases these values may make things worse on that point. The values returned by this function are sorted by a weight combining the lower cache hit joined to the largest memory values allocated.","ref":"recon_alloc.html#cache_hit_rates/0","title":"recon_alloc.cache_hit_rates/0","type":"function"},{"doc":"Compares the block sizes to the carrier sizes, both for single block ( sbcs ) and multiblock ( mbcs ) carriers. The returned results are sorted by a weight system that is somewhat likely to return the most fragmented allocators first, based on their percentage of use and the total size of the carriers, for both sbcs and mbcs . The values can both be returned for current allocator values, and for max allocator values. The current values hold the present allocation numbers, and max values, the values at the peak. Comparing both together can give an idea of whether the node is currently being at its memory peak when possibly leaky, or if it isn't. This information can in turn influence the tuning of allocators to better fit sizes of blocks and/or carriers.","ref":"recon_alloc.html#fragmentation/1","title":"recon_alloc.fragmentation/1","type":"function"},{"doc":"Equivalent to memory(Key, current) .","ref":"recon_alloc.html#memory/1","title":"recon_alloc.memory/1","type":"function"},{"doc":"reports one of multiple possible memory values for the entire node depending on what is to be reported: used reports the memory that is actively used for allocated Erlang data; allocated reports the memory that is reserved by the VM. It includes the memory used, but also the memory yet-to-be-used but still given by the OS. This is the amount you want if you're dealing with ulimit and OS-reported values. allocated_types report the memory that is reserved by the VM grouped into the different util allocators. allocated_instances report the memory that is reserved by the VM grouped into the different schedulers. Note that instance id 0 is the global allocator used to allocate data from non-managed threads, i.e. async and driver threads. unused reports the amount of memory reserved by the VM that is not being allocated. Equivalent to allocated - used . usage returns a percentage (0.0 .. 1.0) of used/allocated memory ratios. The memory reported by allocated should roughly match what the OS reports. If this amount is different by a large margin, it may be the sign that someone is allocating memory in C directly, outside of Erlang's own allocator -- a big warning sign. There are currently three sources of memory alloction that are not counted towards this value: The cached segments in the mseg allocator, any memory allocated as a super carrier, and small pieces of memory allocated during startup before the memory allocators are initialized. Also note that low memory usages can be the sign of fragmentation in memory, in which case exploring which specific allocator is at fault is recommended (see fragmentation/1 )","ref":"recon_alloc.html#memory/2","title":"recon_alloc.memory/2","type":"function"},{"doc":"compares the amount of single block carriers ( sbcs ) vs the number of multiblock carriers ( mbcs ) for each individual allocator in allocator() . When a specific piece of data is allocated, it is compared to a threshold, called the 'single block carrier threshold' ( sbct ). When the data is larger than the sbct , it gets sent to a single block carrier. When the data is smaller than the sbct , it gets placed into a multiblock carrier. mbcs are to be preferred to sbcs because they basically represent pre- allocated memory, whereas sbcs will map to one call to sys_alloc or mseg_alloc, which is more expensive than redistributing data that was obtained for multiblock carriers. Moreover, the VM is able to do specific work with mbcs that should help reduce fragmentation in ways sys_alloc or mmap usually won't. Ideally, most of the data should fit inside multiblock carriers. If most of the data ends up in sbcs , you may need to adjust the multiblock carrier sizes, specifically the maximal value ( lmbcs ) and the threshold ( sbct ). On 32 bit VMs, sbct is limited to 8MBs, but 64 bit VMs can go to pretty much any practical size. Given the value returned is a ratio of sbcs/mbcs, the higher the value, the worst the condition. The list is sorted accordingly.","ref":"recon_alloc.html#sbcs_to_mbcs/1","title":"recon_alloc.sbcs_to_mbcs/1","type":"function"},{"doc":"set the current unit to be used by recon_alloc. This effects all functions that return bytes. Eg. 1 &gt; recon_alloc : memory ( used , current ) . 17548752 2 &gt; recon_alloc : set_unit ( kilobyte ) . undefined 3 &gt; recon_alloc : memory ( used , current ) . 17576.90625","ref":"recon_alloc.html#set_unit/1","title":"recon_alloc.set_unit/1","type":"function"},{"doc":"Take a new snapshot of the current memory allocator statistics. The snapshot is stored in the process dictionary of the calling process, with all the limitations that it implies (i.e. no garbage-collection). To unsert the snapshot, see snapshot_clear/0 .","ref":"recon_alloc.html#snapshot/0","title":"recon_alloc.snapshot/0","type":"function"},{"doc":"clear the current snapshot in the process dictionary, if present, and return the value it had before being unset.","ref":"recon_alloc.html#snapshot_clear/0","title":"recon_alloc.snapshot_clear/0","type":"function"},{"doc":"returns the current snapshot stored by snapshot/0 . Returns undefined if no snapshot has been taken.","ref":"recon_alloc.html#snapshot_get/0","title":"recon_alloc.snapshot_get/0","type":"function"},{"doc":"load a snapshot from a given file. The format of the data in the file can be either the same as output by snapshot_save/1 , or the output obtained by calling {erlang:memory(),[{A,erlang:system_info({allocator,A})} || A &lt;- erlang:system_info(alloc_util_allocators)++[sys_alloc,mseg_alloc]]}. and storing it in a file. If the latter option is taken, please remember to add a full stop at the end of the resulting Erlang term, as this function uses file:consult/1 to load the file. Example usage: On target machine : 1 &gt; recon_alloc : snapshot ( ) . undefined 2 &gt; recon_alloc : memory ( used ) . 18411064 3 &gt; recon_alloc : snapshot_save ( &quot;recon_snapshot.terms&quot; ) . ok On other machine : 1 &gt; recon_alloc : snapshot_load ( &quot;recon_snapshot.terms&quot; ) . undefined 2 &gt; recon_alloc : memory ( used ) . 18411064","ref":"recon_alloc.html#snapshot_load/1","title":"recon_alloc.snapshot_load/1","type":"function"},{"doc":"print a dump of the current snapshot stored by snapshot/0 Prints undefined if no snapshot has been taken.","ref":"recon_alloc.html#snapshot_print/0","title":"recon_alloc.snapshot_print/0","type":"function"},{"doc":"save the current snapshot taken by snapshot/0 to a file. If there is no current snapshot, a snapshot of the current allocator statistics will be written to the file.","ref":"recon_alloc.html#snapshot_save/1","title":"recon_alloc.snapshot_save/1","type":"function"},{"doc":"","ref":"recon_alloc.html#t:allocator/0","title":"recon_alloc.allocator/0","type":"type"},{"doc":"","ref":"recon_alloc.html#t:allocdata/1","title":"recon_alloc.allocdata/1","type":"type"},{"doc":"","ref":"recon_alloc.html#t:allocdata_types/1","title":"recon_alloc.allocdata_types/1","type":"type"},{"doc":"","ref":"recon_alloc.html#t:instance/0","title":"recon_alloc.instance/0","type":"type"},{"doc":"","ref":"recon_alloc.html#t:memory/0","title":"recon_alloc.memory/0","type":"type"},{"doc":"","ref":"recon_alloc.html#t:snapshot/0","title":"recon_alloc.snapshot/0","type":"type"},{"doc":"Regroups useful functionality used by recon when dealing with data from the node. The functions in this module allow quick runtime access to fancier behaviour than what would be done using recon module itself.","ref":"recon_lib.html","title":"recon_lib","type":"module"},{"doc":"Takes a list of terms, and counts how often each of them appears in the list. The list returned is in no particular order.","ref":"recon_lib.html#count/1","title":"recon_lib.count/1","type":"function"},{"doc":"Returns the attributes ( recon:inet_attrs() ) of all inet ports (UDP, SCTP, TCP) of the node.","ref":"recon_lib.html#inet_attrs/1","title":"recon_lib.inet_attrs/1","type":"function"},{"doc":"Returns the attributes required for a given inet port (UDP, SCTP, TCP). This form of attributes is standard for most comparison functions for processes in recon.","ref":"recon_lib.html#inet_attrs/2","title":"recon_lib.inet_attrs/2","type":"function"},{"doc":"Returns a list of all the open ports in the VM, coupled with one of the properties desired from erlang:port_info/1-2 .","ref":"recon_lib.html#port_list/1","title":"recon_lib.port_list/1","type":"function"},{"doc":"Returns a list of all the open ports in the VM, but only if the Attr 's resulting value matches Val . Attr must be a property accepted by erlang:port_info/2 .","ref":"recon_lib.html#port_list/2","title":"recon_lib.port_list/2","type":"function"},{"doc":"Returns the attributes ( recon:proc_attrs() ) of all processes of the node, except the caller.","ref":"recon_lib.html#proc_attrs/1","title":"recon_lib.proc_attrs/1","type":"function"},{"doc":"Returns the attributes of a given process. This form of attributes is standard for most comparison functions for processes in recon. A special attribute is binary_memory , which will reduce the memory used by the process for binary data on the global heap.","ref":"recon_lib.html#proc_attrs/2","title":"recon_lib.proc_attrs/2","type":"function"},{"doc":"Runs a fun once, waits Ms , runs the fun again, and returns both results.","ref":"recon_lib.html#sample/2","title":"recon_lib.sample/2","type":"function"},{"doc":"Diffs two runs of erlang:statistics(scheduler_wall_time) and returns usage metrics in terms of cores and 0..1 percentages.","ref":"recon_lib.html#scheduler_usage_diff/2","title":"recon_lib.scheduler_usage_diff/2","type":"function"},{"doc":"Compare two samples and return a list based on some key. The type mentioned for the structure is diff() ( {Key,Val,Other} ), which is compatible with the recon:proc_attrs() type.","ref":"recon_lib.html#sliding_window/2","title":"recon_lib.sliding_window/2","type":"function"},{"doc":"Returns the top n element of a list of process or inet attributes","ref":"recon_lib.html#sublist_top_n_attrs/2","title":"recon_lib.sublist_top_n_attrs/2","type":"function"},{"doc":"Transforms a given term to a pid.","ref":"recon_lib.html#term_to_pid/1","title":"recon_lib.term_to_pid/1","type":"function"},{"doc":"Transforms a given term to a port","ref":"recon_lib.html#term_to_port/1","title":"recon_lib.term_to_port/1","type":"function"},{"doc":"Calls a given function every Interval milliseconds and supports a fold-like interface (each result is modified and accumulated)","ref":"recon_lib.html#time_fold/6","title":"recon_lib.time_fold/6","type":"function"},{"doc":"Calls a given function every Interval milliseconds and supports a map-like interface (each result is modified and returned)","ref":"recon_lib.html#time_map/5","title":"recon_lib.time_map/5","type":"function"},{"doc":"Equivalent of pid(X,Y,Z) in the Erlang shell.","ref":"recon_lib.html#triple_to_pid/3","title":"recon_lib.triple_to_pid/3","type":"function"},{"doc":"","ref":"recon_lib.html#t:diff/0","title":"recon_lib.diff/0","type":"type"},{"doc":"This module handles formatting maps. It allows for trimming output to selected fields, or to nothing at all. It also adds a label to a printout. To set up a limit for a map, you need to give recon a way to tell the map you want to trim from all the other maps, so you have to provide something like a 'type definition'. It can be either another map which is compared to the arg, or a fun.","ref":"recon_map.html","title":"recon_map","type":"module"},{"doc":"remove all imported definitions, destroy the table, clean up","ref":"recon_map.html#clear/0","title":"recon_map.clear/0","type":"function"},{"doc":"quickly check if we want to do any record formatting","ref":"recon_map.html#is_active/0","title":"recon_map.is_active/0","type":"function"},{"doc":"Limit output to selected keys of a map (can be 'none', 'all', a key or a list of keys). Pattern selects maps to process: a &quot;pattern&quot; is just a map, and if all key/value pairs of a pattern are present in a map (in other words, the pattern is a subset), then we say the map matches and we process it accordingly (apply the limit). Patterns are applied in alphabetical order, until a match is found. Instead of a pattern you can also provide a function which will take a map and return a boolean.","ref":"recon_map.html#limit/3","title":"recon_map.limit/3","type":"function"},{"doc":"prints out all &quot;known&quot; map definitions and their limit settings. Printout tells a map's name, the matching fields required, and the limit options.","ref":"recon_map.html#list/0","title":"recon_map.list/0","type":"function"},{"doc":"remove a given map entry","ref":"recon_map.html#remove/1","title":"recon_map.remove/1","type":"function"},{"doc":"rename a given map entry, which allows to to change priorities for matching. The first argument is the current name, and the second argument is the new name.","ref":"recon_map.html#rename/2","title":"recon_map.rename/2","type":"function"},{"doc":"","ref":"recon_map.html#t:limit/0","title":"recon_map.limit/0","type":"type"},{"doc":"","ref":"recon_map.html#t:map_label/0","title":"recon_map.map_label/0","type":"type"},{"doc":"","ref":"recon_map.html#t:pattern/0","title":"recon_map.pattern/0","type":"type"},{"doc":"This module handles formatting records for known record types. Record definitions are imported from modules by user. Definitions are distinguished by record name and its arity, if you have multiple records of the same name and size, you have to choose one of them and some of your records may be wrongly labelled. You can manipulate your definition list by using import/1 and clear/1, and check which definitions are in use by executing list/0.","ref":"recon_rec.html","title":"recon_rec","type":"module"},{"doc":"remove all imported definitions, destroy the table, clean up","ref":"recon_rec.html#clear/0","title":"recon_rec.clear/0","type":"function"},{"doc":"remove definitions imported from a module.","ref":"recon_rec.html#clear/1","title":"recon_rec.clear/1","type":"function"},{"doc":"returns a list of active record definitions","ref":"recon_rec.html#get_list/0","title":"recon_rec.get_list/0","type":"function"},{"doc":"import record definitions from a module. If a record definition of the same name and arity has already been imported from another module then the new definition is ignored (returned info tells you from which module the existing definition was imported). You have to choose one and possibly remove the old one using clear/1. Supports importing multiple modules at once (by giving a list of atoms as an argument).","ref":"recon_rec.html#import/1","title":"recon_rec.import/1","type":"function"},{"doc":"quickly check if we want to do any record formatting","ref":"recon_rec.html#is_active/0","title":"recon_rec.is_active/0","type":"function"},{"doc":"Limit output to selected fields of a record (can be 'none', 'all', a field or a list of fields). Limit set to 'none' means there is no limit, and all fields are displayed; limit 'all' means that all fields are squashed and only record name will be shown.","ref":"recon_rec.html#limit/3","title":"recon_rec.limit/3","type":"function"},{"doc":"prints out all &quot;known&quot; (imported) record definitions and their limit settings. Printout tells module a record originates from, its name and a list of field names, plus the record's arity (may be handy if handling big records) and a list of field it limits its output to, if set.","ref":"recon_rec.html#list/0","title":"recon_rec.list/0","type":"function"},{"doc":"","ref":"recon_rec.html#t:field/0","title":"recon_rec.field/0","type":"type"},{"doc":"","ref":"recon_rec.html#t:import_result/0","title":"recon_rec.import_result/0","type":"type"},{"doc":"","ref":"recon_rec.html#t:limit/0","title":"recon_rec.limit/0","type":"type"},{"doc":"","ref":"recon_rec.html#t:listentry/0","title":"recon_rec.listentry/0","type":"type"},{"doc":"compound","ref":"recon_rec.html#t:record_name/0","title":"recon_rec.record_name/0","type":"type"},{"doc":"recon_trace is a module that handles tracing in a safe manner for single Erlang nodes, currently for function calls only. Functionality includes: Nicer to use interface (arguably) than dbg or trace BIFs. Protection against dumb decisions (matching all calls on a node being traced, for example) Adding safe guards in terms of absolute trace count or rate-limitting Nicer formatting than default traces Tracing Erlang Code The Erlang Trace BIFs allow to trace any Erlang code at all. They work in two parts: pid specifications, and trace patterns. Pid specifications let you decide which processes to target. They can be specific pids, all pids, existing pids, or new pids (those not spawned at the time of the function call). The trace patterns represent functions. Functions can be specified in two parts: specifying the modules, functions, and arguments, and then with Erlang match specifications to add constraints to arguments (see calls/3 for details). What defines whether you get traced or not is the intersection of both: _ , -- -- -- -- , _ _ , -- -- -- -- , _ , - &#39; `-,,-&#39; ` - , , - &#39; ,-&#39; &#39;-, `-, | Matching -&#39; &#39;- Matching | | Pids | Getting | Trace | | | Traced | Patterns | | -, ,- | &#39; - , &#39;-, ,-&#39; , - &#39; &#39; - , _ _ , - &#39;&#39; - , _ _ , - &#39; &#39; -- -- -- -- &#39; &#39; -- -- -- -- &#39; If either the pid specification excludes a process or a trace pattern excludes a given call, no trace will be received. Example Session First let's trace the queue:new functions in any process: 1 &gt; recon_trace : calls ( { queue , new , &#39;_&#39; } , 1 ) . 1 13 : 14 : 34.086078 &lt; 0.44 . 0 &gt; queue : new ( ) Recon tracer rate limit tripped . The limit was set to 1 trace message at most, and recon let us know when that limit was reached. Let's instead look for all the queue:in/2 calls, to see what it is we're inserting in queues: 2 &gt; recon_trace : calls ( { queue , in , 2 } , 1 ) . 1 13 : 14 : 55.365157 &lt; 0.44 . 0 &gt; queue : in ( a , { [ ] , [ ] } ) Recon tracer rate limit tripped . In order to see the content we want, we should change the trace patterns to use a fun that matches on all arguments in a list ( _ ) and returns return_trace() . This last part will generate a second trace for each call that includes the return value: 3 &gt; recon_trace : calls ( { queue , in , fun ( _ ) -&gt; return_trace ( ) end } , 3 ) . 1 13 : 15 : 27.655132 &lt; 0.44 . 0 &gt; queue : in ( a , { [ ] , [ ] } ) 13 : 15 : 27.655467 &lt; 0.44 . 0 &gt; queue : in / 2 -- &gt; { [ a ] , [ ] } 13 : 15 : 27.757921 &lt; 0.44 . 0 &gt; queue : in ( a , { [ ] , [ ] } ) Recon tracer rate limit tripped . Matching on argument lists can be done in a more complex manner: 4 &gt; recon_trace : calls ( 4 &gt; { queue , &#39;_&#39; , fun ( [ A , _ ] ) when is_list ( A ) ; is_integer ( A ) andalso A &gt; 1 -&gt; return_trace ( ) end } , 4 &gt; { 10 , 100 } 4 &gt; ) . 32 13 : 24 : 21.324309 &lt; 0.38 . 0 &gt; queue : in ( 3 , { [ ] , [ ] } ) 13 : 24 : 21.371473 &lt; 0.38 . 0 &gt; queue : in / 2 -- &gt; { [ 3 ] , [ ] } 13 : 25 : 14.694865 &lt; 0.53 . 0 &gt; queue : split ( 4 , { [ 10 , 9 , 8 , 7 ] , [ 1 , 2 , 3 , 4 , 5 , 6 ] } ) 13 : 25 : 14.695194 &lt; 0.53 . 0 &gt; queue : split / 2 -- &gt; { { [ 4 , 3 , 2 ] , [ 1 ] } , { [ 10 , 9 , 8 , 7 ] , [ 5 , 6 ] } } 5 &gt; recon_trace : clear ( ) . ok Note that in the pattern above, no specific function ( '_' ) was matched against. Instead, the fun used restricted functions to those having two arguments, the first of which is either a list or an integer greater than 1 . The limit was also set using {10,100} instead of an integer, making the rate-limitting at 10 messages per 100 milliseconds, instead of an absolute value. Any tracing can be manually interrupted by calling recon_trace:clear() , or killing the shell process. Be aware that extremely broad patterns with lax rate-limitting (or very high absolute limits) may impact your node's stability in ways recon_trace cannot easily help you with. In doubt, start with the most restrictive tracing possible, with low limits, and progressively increase your scope. See calls/3 for more details and tracing possibilities. Structure This library is production-safe due to taking the following structure for tracing: [ IO / Group leader ] &lt;- -- -- -- -- -- -- -- -- -- -- , | | [ shell ] -- -&gt; [ tracer process ] -- -- &gt; [ formatter ] The tracer process receives trace messages from the node, and enforces limits in absolute terms or trace rates, before forwarding the messages to the formatter. This is done so the tracer can do as little work as possible and never block while building up a large mailbox. The tracer process is linked to the shell, and the formatter to the tracer process. The formatter also traps exits to be able to handle all received trace messages until the tracer termination, but will then shut down as soon as possible. In case the operator is tracing from a remote shell which gets disconnected, the links between the shell and the tracer should make it so tracing is automatically turned off once you disconnect. If sending output to the Group Leader is not desired, you may specify a different pid() via the option io_server in the calls/3 function. For instance to write the traces to a file you can do something like 1 &gt; { ok , Dev } = file : open ( &quot;/tmp/trace&quot; , [ write ] ) . 2 &gt; recon_trace : calls ( { queue , in , fun ( _ ) -&gt; return_trace ( ) end } , 3 , [ { io_server , Dev } ] ) . 1 3 &gt; Recon tracer rate limit tripped . 4 &gt; file : close ( Dev ) . The only output still sent to the Group Leader is the rate limit being tripped, and any errors. The rest will be sent to the other IO server (see http://erlang.org/doc/apps/stdlib/io_protocol.html ). Record Printing Thanks to code contributed by Bartek Górny, record printing can be added to traces by first importing records in an active session with recon_rec:import([Module, ...]) , after which the records declared in the module list will be supported.","ref":"recon_trace.html","title":"recon_trace","type":"module"},{"doc":"Equivalent to calls({Mod, Fun, Args}, Max, []) .","ref":"recon_trace.html#calls/2","title":"recon_trace.calls/2","type":"function"},{"doc":"Allows to set trace patterns and pid specifications to trace function calls. The basic calls take the trace patterns as tuples of the form {Module, Function, Args} where: Module is any atom representing a module Function is any atom representing a function, or the wildcard '_' Args is either the arity of a function ( 0..255 ), a wildcard pattern ( '_' ), a match specification , or a function from a shell session that can be transformed into a match specification There is also an argument specifying either a maximal count (a number) of trace messages to be received, or a maximal frequency ( {Num, Millisecs} ). Here are examples of things to trace: All calls from the queue module, with 10 calls printed at most: recon_trace:calls({queue, '_', '_'}, 10) All calls to lists:seq(A,B) , with 100 calls printed at most: recon_trace:calls({lists, seq, 2}, 100) All calls to lists:seq(A,B) , with 100 calls per second at most: recon_trace:calls({lists, seq, 2}, {100, 1000}) All calls to lists:seq(A,B,2) (all sequences increasing by two) with 100 calls at most: recon_trace:calls({lists, seq, fun([_,_,2]) -&gt; ok end}, 100) All calls to iolist_to_binary/1 made with a binary as an argument already (kind of useless conversion!): recon_trace:calls({erlang, iolist_to_binary, fun([X]) when is_binary(X) -&gt; ok end}, 10) Calls to the queue module only in a given process Pid , at a rate of 50 per second at most: recon_trace:calls({queue, '_', '_'}, {50,1000}, [{pid, Pid}]) Print the traces with the function arity instead of literal arguments: recon_trace:calls(TSpec, Max, [{args, arity}]) Matching the filter/2 functions of both dict and lists modules, across new processes only: recon_trace:calls([{dict,filter,2},{lists,filter,2}], 10, [{pid, new}]) Tracing the handle_call/3 functions of a given module for all new processes, and those of an existing one registered with gproc : recon_trace:calls({Mod,handle_call,3}, {10,100}, [{pid, [{via, gproc, Name}, new]} Show the result of a given function call: recon_trace:calls({Mod,Fun,fun(_) -&gt; return_trace() end}, Max, Opts) or recon_trace:calls({Mod,Fun,[{'_', [], [{return_trace}]}]}, Max, Opts) , the important bit being the return_trace() call or the {return_trace} match spec value. A short-hand version for this pattern of 'match anything, trace everything' for a function is recon_trace:calls({Mod, Fun, return_trace}) . There's a few more combination possible, with multiple trace patterns per call, and more options: {pid, PidSpec} : which processes to trace. Valid options is any of all , new , existing , or a process descriptor ( {A,B,C} , &quot;&lt;A.B.C&gt;&quot; , an atom representing a name, {global, Name} , {via, Registrar, Name} , or a pid). It's also possible to specify more than one by putting them in a list. {timestamp, formatter | trace} : by default, the formatter process adds timestamps to messages received. If accurate timestamps are required, it's possible to force the usage of timestamps within trace messages by adding the option {timestamp, trace} . {args, arity | args} : whether to print arity in function calls or their (by default) literal representation. {scope, global | local} : by default, only 'global' (fully qualified function calls) are traced, not calls made internally. To force tracing of local calls, pass in {scope, local} . This is useful whenever you want to track the changes of code in a process that isn't called with Module:Fun(Args) , but just Fun(Args) . {formatter, fun(Term) -&gt; io_data() end} : override the default formatting functionality provided by recon. {io_server, pid() | atom()} : by default, recon logs to the current group leader, usually the shell. This option allows to redirect trace output to a different IO server (such as a file handle). return_to : If this option is set (in conjunction with the match option {scope, local} ), the function to which the value is returned is output in a trace. Note that this is distinct from giving the *caller* since exception handling or calls in tail position may hide the original caller. Also note that putting extremely large Max values (i.e. 99999999 or {10000,1} ) will probably negate most of the safe-guarding this library does and be dangerous to your node. Similarly, tracing extremely large amounts of function calls (all of them, or all of io for example) can be risky if more trace messages are generated than any process on the node could ever handle, despite the precautions taken by this library.","ref":"recon_trace.html#calls/3","title":"recon_trace.calls/3","type":"function"},{"doc":"Stops all tracing at once.","ref":"recon_trace.html#clear/0","title":"recon_trace.clear/0","type":"function"},{"doc":"","ref":"recon_trace.html#format/1","title":"recon_trace.format/1","type":"function"},{"doc":"formats call arguments and return values - most types are just printed out, except for tuples recognised as records, which mimic the source code syntax","ref":"recon_trace.html#format_trace_output/1","title":"recon_trace.format_trace_output/1","type":"function"},{"doc":"","ref":"recon_trace.html#format_trace_output/2","title":"recon_trace.format_trace_output/2","type":"function"},{"doc":"","ref":"recon_trace.html#t:args/0","title":"recon_trace.args/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:fn/0","title":"recon_trace.fn/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:formatterfun/0","title":"recon_trace.formatterfun/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:matchspec/0","title":"recon_trace.matchspec/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:max/0","title":"recon_trace.max/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:max_rate/0","title":"recon_trace.max_rate/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:max_traces/0","title":"recon_trace.max_traces/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:millisecs/0","title":"recon_trace.millisecs/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:mod/0","title":"recon_trace.mod/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:num_matches/0","title":"recon_trace.num_matches/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:options/0","title":"recon_trace.options/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:pidspec/0","title":"recon_trace.pidspec/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:shellfun/0","title":"recon_trace.shellfun/0","type":"type"},{"doc":"","ref":"recon_trace.html#t:tspec/0","title":"recon_trace.tspec/0","type":"type"},{"doc":"Recon is a library to be dropped into any other Erlang project, to be used to assist DevOps people diagnose problems in production nodes. The source code can be obtained from the github repo . A toy application to experiment with can be found at recon_demo .","ref":"overview.html","title":"Overview","type":"extras"},{"doc":"Add recon to your project by adding it as a dependency. With rebar3 this is done as: { deps , [ recon ] } . If you are using releases, make sure to add recon to this list of applications bundled in: { relx , [ { release , { myrel , &quot;0.1.0&quot; } , [ myapp , recon , % &lt;- - here sasl ] } , ... ] } .","ref":"overview.html#installing","title":"Overview - Installing","type":"extras"},{"doc":"Call rebar3 check","ref":"overview.html#running-tests","title":"Overview - Running tests","type":"extras"},{"doc":"Each module in the API describes how it should be used in a stand-alone manner. Insights about how to debug a production Erlang system, often relying on this library, can be found in the free online book Erlang in Anger . The library also contains a few basic scripts that have proven useful in the past but may not be as much today in its script/ directory. These include ways to visualize application dependencies, and a few short scripts to extract high-level information from crashdumps.","ref":"overview.html#using-it","title":"Overview - Using it","type":"extras"},{"doc":"Branches are organized by version. master contains the bleeding edge, 2.x contains all stable changes up to the latest release of v2, and 1.x contains all stable changes of the first version of Recon.","ref":"changelog.html","title":"Changelog","type":"extras"},{"doc":"Handle dead processes in recon:info/2 types and edge cases Reworking documentation structure to support ex_doc and fit in with hex standard","ref":"changelog.html#2-5-3","title":"Changelog - 2.5.3","type":"extras"},{"doc":"Increase Dialyzer strictness Accumulate all block entries in format_blocks option io_server can also be an atom() in traces doc","ref":"changelog.html#2-5-2","title":"Changelog - 2.5.2","type":"extras"},{"doc":"Fix support for extra messages in traces (thanks to Péter Gömöri) Fix some typespecs for match specs (thanks to @chenduo) Support OTP-23 change of format in allocator blocks related to carrier migration support","ref":"changelog.html#2-5-1","title":"Changelog - 2.5.1","type":"extras"},{"doc":"Optional formatting of records in traces (thanks to @bartekgorny) Basic support for OTP-22 in recon_alloc (base handling of foreign_blocks type)","ref":"changelog.html#2-5-0","title":"Changelog - 2.5.0","type":"extras"},{"doc":"Optional formatting of records in traces (thanks to @bartekgorny)","ref":"changelog.html#2-4-0","title":"Changelog - 2.4.0","type":"extras"},{"doc":"Adapting for OTP-21. Includes the 'deprecation' of recon:files/0 since OTP-21 no longer supports listing all file descriptors, and removing error_logger_queue_len from node stats since a new logging mechanism was introduced in-process instead.","ref":"changelog.html#2-3-6","title":"Changelog - 2.3.6","type":"extras"},{"doc":"fixing timefold's first iteration to prevent errors at call-site by sleeping before sampling","ref":"changelog.html#2-3-5","title":"Changelog - 2.3.5","type":"extras"},{"doc":"fixing edoc tag that broke some downstream packaging attempts","ref":"changelog.html#2-3-4","title":"Changelog - 2.3.4","type":"extras"},{"doc":"fixing bin_leak arith errors fixes to recon_alloc:allocators/1 (incl. R16 compatibility) fix errors in scheduler wall time calculations term_to_pid supports binaries","ref":"changelog.html#2-3-3","title":"Changelog - 2.3.3","type":"extras"},{"doc":"Allow the return_to option in recon_trace More efficient sorting function for procs and ports attributes (thanks to @zhongwencool and @pichi) Allow the usage of return_trace in recon_trace:calls/2-3 instead of fun(_) -&gt; return_trace() end .","ref":"changelog.html#2-3-2","title":"Changelog - 2.3.2","type":"extras"},{"doc":"Updated app_deps script to run with rebar3 dependencies Minor docs update","ref":"changelog.html#2-3-1","title":"Changelog - 2.3.1","type":"extras"},{"doc":"Doc made clearer around semantics of recon:proc_count and recon:proc_window . Fix doc typos Fix potential race condition on waiting for death of tracing process Add an option which allows sending tracing output somewhere other than group_leader() (thanks @djnym) Add ability to pass custom formatter function when tracing (thanks @iilyak)","ref":"changelog.html#2-3-0","title":"Changelog - 2.3.0","type":"extras"},{"doc":"Fixing type specs for recon:port_types/0 and recon_lib:count/1 , thanks to @lucafavatella Minor documentation fixes.","ref":"changelog.html#2-2-1","title":"Changelog - 2.2.1","type":"extras"},{"doc":"Adding scheduler info metrics to get a more accurate picture than what top and CPU gives. Broadening recon_trace:calls/2 interface to allow multiple match specs, which was currently only allowed for calls/3 . Support for mbcs_pool data in erts_alloc , and some internal refactoring, thanks to Lukas Larsson.","ref":"changelog.html#2-2-0","title":"Changelog - 2.2.0","type":"extras"},{"doc":"Fixing tests for R15B02 and up Fixing a backwards compatibility for R15B03 on recon_alloc operations with dumps on disk","ref":"changelog.html#2-1-2","title":"Changelog - 2.1.2","type":"extras"},{"doc":"Renaming recon_trace:mfa() type to recon_trace:tspec() to avoid issues in older Erlang versions regarding redefining an existing type (Thanks Roberto Aloi)","ref":"changelog.html#2-1-1","title":"Changelog - 2.1.1","type":"extras"},{"doc":"Adding recon_trace script to allow safe tracing of function calls on production nodes. Adding queue_fun.awk script to inspect running functions of processes with large mailboxes in a crash dump.","ref":"changelog.html#2-1-0","title":"Changelog - 2.1.0","type":"extras"},{"doc":"Preventing crashes in recon_alloc when certain expected allocators do not return results (Thanks to Michal Ptaszek)","ref":"changelog.html#2-0-2","title":"Changelog - 2.0.2","type":"extras"},{"doc":"Add support for R16B03 in recon_alloc .","ref":"changelog.html#2-0-1","title":"Changelog - 2.0.1","type":"extras"},{"doc":"Test suite added Major rewrite of recon_alloc , thanks to Lukas Larsson. Things that changed include: average_sizes/0 is renamed average_block_sizes/1 and now takes the keywords current and max . Documentation updates. memory/1 has new options in allocated_types and allocated_instances . memory/2 has been added, which allows to choose between current and max values. memory(Term) is made equivalent to memory(Term, current) . Allow sbcs_to_mbcs/0 to take the arguments current and max . Added unit conversion function set_unit/1 , which allows to get the recon_alloc results in bytes (default), kilobytes, megabytes, and gigabytes, to help with readability. Updated the internal rebar version, if anybody were to use it. recon:port_info/1 no longer includes the parallelism option by default within the meta category as this would hurt backwards compatibility on some installations. recon:get_state/2 is added in order to specify timeouts. recon:get_state/1 keeps its 5000 milliseconds timeout. Addition of a fake attribute called binary_memory , which is callable in recon:info/2,4 , recon:proc_count/2 , and recon:proc_window/3 . This attribute allows to fetch the amount of memory used by refc binaries for a process, and to sort by that value for counts and windows.","ref":"changelog.html#2-0-0","title":"Changelog - 2.0.0","type":"extras"},{"doc":"add recon_alloc:snapshot* functions, which allow memory allocation snapshots to be taken, saved on disk, reloaded, and analyzed on-demand. Thanks to Lukas Larsson for this functionality. remove parallelism data from port_info for better OTP backwards compatibility with little loss of information.","ref":"changelog.html#1-2-0","title":"Changelog - 1.2.0","type":"extras"},{"doc":"add recon_lib:term_to_port to convert a string back to a usable port. add recon:port_info/1 and recon:port_info/2 add recon_alloc module","ref":"changelog.html#1-1-0","title":"Changelog - 1.1.0","type":"extras"},{"doc":"add info/2 and info/4 . The memory info type thus gets renamed to memory_used , in order to avoid conflicts when picking between a type and a specific process attribute. Types exported by the module also get updated.","ref":"changelog.html#1-0-0","title":"Changelog - 1.0.0","type":"extras"},{"doc":"extended app_deps.erl to read apps/ directories for releases","ref":"changelog.html#0-4-2","title":"Changelog - 0.4.2","type":"extras"},{"doc":"fixed bug where nodes with lots of processes could see the GC call fail if said processes failed between long calls within the bin_leak function call.","ref":"changelog.html#0-4-1","title":"Changelog - 0.4.1","type":"extras"},{"doc":"fixed bug where nodes with lots of processes or ports could see their count or window functions fail because a process or socket closed between the time the function started and before it finished. This ends up changing the API in recon_lib for the window and count functions that take a specific pid as an argument.","ref":"changelog.html#0-4-0","title":"Changelog - 0.4.0","type":"extras"},{"doc":"factored out some logic from recon:info/1 into recon_lib:term_to_pid and allowed arbitrary terms to be used for pids in recon:get_state/1 .","ref":"changelog.html#0-3-1","title":"Changelog - 0.3.1","type":"extras"},{"doc":"Copyright (c) 2012-2023, Fred Hebert All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. The names of its contributors may not be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","ref":"license.html","title":"License","type":"extras"}]